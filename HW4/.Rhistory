store_median = rep(NA, 10000)
for(i in 1:10000) {
store_median[i] = median(sample(Boston$medv, length(Boston$medv), rep=TRUE))
}
median_boot = mean(store_median)
se_med_boot = sd(store_median)
cat(" Est. Median:      ", median_medv, "\n",
"Bootstrap Median: ", median_boot, "\n\n",
"Est. Median SE:   ", se_med_boot)
# Estimating Quantile
q_ten = quantile(Boston$medv, .10)
# Boot strap method
store_quantiles = rep(NA, 10000)
for(i in 1:10000) {
store_quantiles[i] = quantile(sample(Boston$medv, length(Boston$medv), rep=TRUE), probs = .10)
}
for(i in 1:10000) {
store_quantiles[i] = quantile(sample(Boston$medv, length(Boston$medv), rep=TRUE), probs = .10)
}
q_ten_boot = mean(store_quantiles)
q_ten_boot = mean(store_quantiles)
se_q_ten_boot = sd(store_quantiles)
cat(" Est. 10th Prcntl:      ", q_ten, "\n",
"Bootstrap 10th Prcntl: ", q_ten_boot, "\n\n",
"SE Bootstrap:          ", se_q_ten_boot)
## Part a ##
rm(list=ls())
x = rnorm(100)
eps = rnorm(100)
x
x
y =
x[1:10,]
y =
x[1:10]
y =
dim(x)
x
x[1]
y = 2 + 4x + 6x^2 + 8x^3 + eps
for(i in 1:100) {
y[i] = 2 + 4x[i] + 6x[i]^2 + 8x[i]^3 + eps[i]
for(i in 1:100) {
y[i] = 2 + 4x[i] + 6x[i]^2 + 8x[i]^3 + eps[i]
rm(eps)
y = 1 + x + I(x^2) + I(x^3) + rnorm(100)
y
plot(x,y)
set.seed(1112)
x = rnorm(100)
y = 1 + x + I(x^2) + I(x^3) + rnorm(100)
plot(x,y)
?combn
?regsubsets
install.packages("leaps")
install.packages("leaps")
install.packages("leaps")
install.packages("leaps")
setwd("~/Desktop/Statlearning/Homework/HW4")
library(ggplot2)
# Initialize function for calculating values
func_g = function(n) {
return (1 - (1 - (1/n))^n)
}
# Sequence from 1 to 100,000
n_values = 1:100000
# Applying func_g over the sequence
g_values = sapply(n_values, func_g)
# Combining n_values and g_values into a dataframe
df_g = data.frame(n = n_values, p = g_values)
# Displaying the first few rows of the dataframe
head(df_g)
# Plotting
plot(df_g$n, df_g$p, log = "x", xaxt = "n", type = "l",
xlab = "n (log10 scale)", ylab = "p(j)",
main = "Probability of jth obs appearing")
axis(1, at = 10^seq(0, 5, by = 1), labels = 10^seq(0, 5, by = 1))
store = rep(NA, 10000)
for(i in 1:10000) {
store[i] = sum(sample(1:100, rep=TRUE) == 4) > 0
}
mean(store)
set.seed(777)
store = rep(NA, 10000)
for(i in 1:10000) {
store[i] = sum(sample(1:100, rep=TRUE) == 4) > 0
}
mean(store)
rm(list = ls())
rm(list = ls())
# Generating simulated data
set.seed(1)
x = rnorm(100)
y = x - 2 * x^2 + rnorm(100)
plot(x,y,
main = "Plot of X vs Y")
set.seed(1789)
# Setting initial data frame and error df
df_c = data.frame(x, y)
n = length(df_c$x)
errors_c = data.frame(model_i=rep(NA, n),
model_ii=rep(NA, n),
model_iii=rep(NA, n),
model_iv=rep(NA, n))
# Running LOOCV
for (i in 1:n) {
# Define the training and test sets
train = df_c[-i, ]
test = df_c[i, ]
# Fit the four models
model_i = lm(y ~ x, data=train)
model_ii = lm(y ~ x + I(x^2), data=train)
model_iii = lm(y ~ x + I(x^2) + I(x^3), data=train)
model_iv = lm(y ~ x + I(x^2) + I(x^3) + I(x^4), data=train)
# Make predictions and calculate errors
pred_i = predict(model_i, newdata=test)
pred_ii = predict(model_ii, newdata=test)
pred_iii = predict(model_iii, newdata=test)
pred_iv = predict(model_iv, newdata=test)
errors_c$model_i[i] = test$y - pred_i
errors_c$model_ii[i] = test$y - pred_ii
errors_c$model_iii[i] = test$y - pred_iii
errors_c$model_iv[i] = test$y - pred_iv
}
# View the first few rows of the errors dataframe
head(errors_c)
set.seed(1231)
errors_c2 = data.frame(model_i=rep(NA, n),
model_ii=rep(NA, n),
model_iii=rep(NA, n),
model_iv=rep(NA, n))
# Running LOOCV
for (i in 1:n) {
# Define the training and test sets
train = df_c[-i, ]
test = df_c[i, ]
# Fit the four models
model_i2 = lm(y ~ x, data=train)
model_ii2 = lm(y ~ x + I(x^2), data=train)
model_iii2 = lm(y ~ x + I(x^2) + I(x^3), data=train)
model_iv2 = lm(y ~ x + I(x^2) + I(x^3) + I(x^4), data=train)
# Make predictions and calculate errors
pred_i2 = predict(model_i2, newdata=test)
pred_ii2 = predict(model_ii2, newdata=test)
pred_iii2 = predict(model_iii2, newdata=test)
pred_iv2 = predict(model_iv2, newdata=test)
errors_c2$model_i[i] = test$y - pred_i2
errors_c2$model_ii[i] = test$y - pred_ii2
errors_c2$model_iii[i] = test$y - pred_iii2
errors_c2$model_iv[i] = test$y - pred_iv2
}
print(sum(errors_c == errors_c2))
cat(" Model i mean", mean(errors_c$model_i), "\n\n",
"Model ii mean", mean(errors_c$model_ii), "\n\n",
"Model iii mean", mean(errors_c$model_iii), "\n\n",
"Model iv mean", mean(errors_c$model_iv))
summary(model_i)
summary(model_ii)
summary(model_iii)
summary(model_iv)
rm(list=ls())
#install.packages("ISLR2")
library(ISLR2)
data("Boston")
attach(Boston)
# Estimate for popultation mean and standard error
mu_medv = mean(Boston$medv)
se_medv = sqrt(var(Boston$medv)) / sqrt(length(Boston$medv))
set.seed(1989)
set.seed(1989)
store = rep(NA, 10000)
for(i in 1:10000) {
store[i] = mean(sample(Boston$medv, length(Boston$medv), rep=TRUE))
}
mu_boot = mean(store)
se_boot = sd(store)
cat(" Est. Mean: ", mu_medv, "\n",
"Bootstrap: ", mu_boot, "\n\n",
"Est. SE:   ", se_medv, "\n",
"Bootstrap: ", se_boot)
# 95 CI for the mean of medv:
UCI = mu_boot + 2*se_boot
LCI = mu_boot - 2*se_boot
cat(" 95% Confidence Interval for Mean medv:\n\n",
"[",LCI,",",UCI,"]")
t.test(Boston$medv)
set.seed(1992)
set.seed(1992)
# Median
median_medv = median(Boston$medv)
# Boot strap method to find standard error
store_median = rep(NA, 10000)
for(i in 1:10000) {
store_median[i] = median(sample(Boston$medv, length(Boston$medv), rep=TRUE))
}
median_boot = mean(store_median)
se_med_boot = sd(store_median)
cat(" Est. Median:      ", median_medv, "\n",
"Bootstrap Median: ", median_boot, "\n\n",
"Est. Median SE:   ", se_med_boot)
set.seed(1234)
set.seed(1234)
# Estimating Quantile
q_ten = quantile(Boston$medv, .10)
# Boot strap method
store_quantiles = rep(NA, 10000)
for(i in 1:10000) {
store_quantiles[i] = quantile(sample(Boston$medv, length(Boston$medv), rep=TRUE), probs = .10)
}
q_ten_boot = mean(store_quantiles)
se_q_ten_boot = sd(store_quantiles)
cat(" Est. 10th Prcntl:      ", q_ten, "\n",
"Bootstrap 10th Prcntl: ", q_ten_boot, "\n\n",
"SE Bootstrap:          ", se_q_ten_boot)
rm(list=ls())
set.seed(1112)
x = rnorm(100)
y = 1 + x + I(x^2) + I(x^3) + rnorm(100)
plot(x,y)
install.packages("leaps")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Desktop/Statlearning/Homework/HW4")
library(ggplot2)
# Initialize function for calculating values
func_g = function(n) {
return (1 - (1 - (1/n))^n)
}
# Sequence from 1 to 100,000
n_values = 1:100000
# Applying func_g over the sequence
g_values = sapply(n_values, func_g)
# Combining n_values and g_values into a dataframe
df_g = data.frame(n = n_values, p = g_values)
# Displaying the first few rows of the dataframe
head(df_g)
# Plotting
plot(df_g$n, df_g$p, log = "x", xaxt = "n", type = "l",
xlab = "n (log10 scale)", ylab = "p(j)",
main = "Probability of jth obs appearing")
axis(1, at = 10^seq(0, 5, by = 1), labels = 10^seq(0, 5, by = 1))
set.seed(777)
store = rep(NA, 10000)
for(i in 1:10000) {
store[i] = sum(sample(1:100, rep=TRUE) == 4) > 0
}
mean(store)
rm(list = ls())
# Generating simulated data
set.seed(1)
x = rnorm(100)
y = x - 2 * x^2 + rnorm(100)
plot(x,y,
main = "Plot of X vs Y")
set.seed(1789)
# Setting initial data frame and error df
df_c = data.frame(x, y)
n = length(df_c$x)
errors_c = data.frame(model_i=rep(NA, n),
model_ii=rep(NA, n),
model_iii=rep(NA, n),
model_iv=rep(NA, n))
# Running LOOCV
for (i in 1:n) {
# Define the training and test sets
train = df_c[-i, ]
test = df_c[i, ]
# Fit the four models
model_i = lm(y ~ x, data=train)
model_ii = lm(y ~ x + I(x^2), data=train)
model_iii = lm(y ~ x + I(x^2) + I(x^3), data=train)
model_iv = lm(y ~ x + I(x^2) + I(x^3) + I(x^4), data=train)
# Make predictions and calculate errors
pred_i = predict(model_i, newdata=test)
pred_ii = predict(model_ii, newdata=test)
pred_iii = predict(model_iii, newdata=test)
pred_iv = predict(model_iv, newdata=test)
errors_c$model_i[i] = test$y - pred_i
errors_c$model_ii[i] = test$y - pred_ii
errors_c$model_iii[i] = test$y - pred_iii
errors_c$model_iv[i] = test$y - pred_iv
}
# View the first few rows of the errors dataframe
head(errors_c)
set.seed(1231)
errors_c2 = data.frame(model_i=rep(NA, n),
model_ii=rep(NA, n),
model_iii=rep(NA, n),
model_iv=rep(NA, n))
# Running LOOCV
for (i in 1:n) {
# Define the training and test sets
train = df_c[-i, ]
test = df_c[i, ]
# Fit the four models
model_i2 = lm(y ~ x, data=train)
model_ii2 = lm(y ~ x + I(x^2), data=train)
model_iii2 = lm(y ~ x + I(x^2) + I(x^3), data=train)
model_iv2 = lm(y ~ x + I(x^2) + I(x^3) + I(x^4), data=train)
# Make predictions and calculate errors
pred_i2 = predict(model_i2, newdata=test)
pred_ii2 = predict(model_ii2, newdata=test)
pred_iii2 = predict(model_iii2, newdata=test)
pred_iv2 = predict(model_iv2, newdata=test)
errors_c2$model_i[i] = test$y - pred_i2
errors_c2$model_ii[i] = test$y - pred_ii2
errors_c2$model_iii[i] = test$y - pred_iii2
errors_c2$model_iv[i] = test$y - pred_iv2
}
print(sum(errors_c == errors_c2))
cat(" Model i mean", mean(errors_c$model_i), "\n\n",
"Model ii mean", mean(errors_c$model_ii), "\n\n",
"Model iii mean", mean(errors_c$model_iii), "\n\n",
"Model iv mean", mean(errors_c$model_iv))
summary(model_i)
summary(model_ii)
summary(model_iii)
summary(model_iv)
rm(list=ls())
#install.packages("ISLR2")
library(ISLR2)
data("Boston")
attach(Boston)
# Estimate for popultation mean and standard error
mu_medv = mean(Boston$medv)
se_medv = sqrt(var(Boston$medv)) / sqrt(length(Boston$medv))
set.seed(1989)
store = rep(NA, 10000)
for(i in 1:10000) {
store[i] = mean(sample(Boston$medv, length(Boston$medv), rep=TRUE))
}
mu_boot = mean(store)
se_boot = sd(store)
cat(" Est. Mean: ", mu_medv, "\n",
"Bootstrap: ", mu_boot, "\n\n",
"Est. SE:   ", se_medv, "\n",
"Bootstrap: ", se_boot)
# 95 CI for the mean of medv:
UCI = mu_boot + 2*se_boot
LCI = mu_boot - 2*se_boot
cat(" 95% Confidence Interval for Mean medv:\n\n",
"[",LCI,",",UCI,"]")
t.test(Boston$medv)
set.seed(1992)
# Median
median_medv = median(Boston$medv)
# Boot strap method to find standard error
store_median = rep(NA, 10000)
for(i in 1:10000) {
store_median[i] = median(sample(Boston$medv, length(Boston$medv), rep=TRUE))
}
median_boot = mean(store_median)
se_med_boot = sd(store_median)
cat(" Est. Median:      ", median_medv, "\n",
"Bootstrap Median: ", median_boot, "\n\n",
"Est. Median SE:   ", se_med_boot)
set.seed(1234)
# Estimating Quantile
q_ten = quantile(Boston$medv, .10)
# Boot strap method
store_quantiles = rep(NA, 10000)
for(i in 1:10000) {
store_quantiles[i] = quantile(sample(Boston$medv, length(Boston$medv), rep=TRUE), probs = .10)
}
q_ten_boot = mean(store_quantiles)
se_q_ten_boot = sd(store_quantiles)
cat(" Est. 10th Prcntl:      ", q_ten, "\n",
"Bootstrap 10th Prcntl: ", q_ten_boot, "\n\n",
"SE Bootstrap:          ", se_q_ten_boot)
rm(list=ls())
set.seed(1112)
x = rnorm(100)
y = 1 + x + I(x^2) + I(x^3) + rnorm(100)
plot(x,y)
install.packages("leaps")
# Initialize Null Model
# Set # params
# Model out NcK Parameter models (10c1)
# combn
# install.packages("leaps")
library(leaps)
?regsubsets
regfit.full = regsubsets(y ~ x, nvmax = 10)
x_df = data.frame(x1=x,
x2=I(x^2),
x3=I(x^3),
x4=I(x^4),
x5=I(x^5),
x6=I(x^6),
x7=I(x^7),
x8=I(x^8),
x9=I(x^9),
x10=I(x^10))
head(x)
head(x_df)
regfit.full = regsubsets(y ~ ., data = x_df, nvmax = 10)
reg.summary = summary(regfit.full)
reg.summary
reg.summary
reg.summary$which
reg.summary$cp
plot(reg.summary$cp)
plot(reg.summary$cp,
type = line)
plot(reg.summary$cp,
type = "line")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp",
title(main = "Cp"))
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp",
main = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC",
main = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2",
main = "Adjusted R2")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp",
main = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC",
main = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2",
main = "Adjusted R2")
title(main = "Best Subset Selection", sub = "Cp, BIC, Adj R2")
par(mfrow = c(3,1))
plot(reg.summary$cp,
type = "line",
xlab = "# Predictors",
ylab = "Cp",
main = "Cp")
plot(reg.summary$bic,
type = "line",
xlab = "# Predictors",
ylab = "BIC",
main = "BIC")
plot(reg.summary$adjr2,
type = "line",
xlab = "# Predictors",
ylab = "Adjusted R2",
main = "Adjusted R2")
